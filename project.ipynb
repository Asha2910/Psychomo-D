{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5664fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf716c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(r\"C:\\Users\\Asha\\Desktop\\AIML PROJECT\\haarcascade_frontalface_default.xml\")\n",
    "classifier =load_model(r\"C:\\Users\\Asha\\Desktop\\AIML PROJECT\\model.h5\")\n",
    "\n",
    "emotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "            prediction = classifier.predict(roi)[0]\n",
    "            label=emotion_labels[prediction.argmax()]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f22341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "\"\"\"Utilies for image preprocessing and augmentation.\n",
    "\n",
    "Deprecated: `tf.keras.preprocessing.image` APIs do not operate on tensors and\n",
    "are not recommended for new code. Prefer loading data with\n",
    "`tf.keras.utils.image_dataset_from_directory`, and then transforming the output\n",
    "`tf.data.Dataset` with preprocessing layers. For more information, see the\n",
    "tutorials for [loading images](\n",
    "https://www.tensorflow.org/tutorials/load_data/images) and [augmenting images](\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation), as well as the\n",
    "[preprocessing layer guide](\n",
    "https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "import multiprocessing\n",
    "import os\n",
    "import threading\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend\n",
    "from keras.utils import data_utils\n",
    "from keras.utils import image_utils\n",
    "from keras.utils import io_utils\n",
    "\n",
    "# isort: off\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy import linalg  # noqa: F401\n",
    "    from scipy import ndimage  # noqa: F401\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    from PIL import ImageEnhance\n",
    "except ImportError:\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.Iterator\")\n",
    "class Iterator(data_utils.Sequence):\n",
    "    \"\"\"Base class for image data iterators.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.Iterator` is not recommended for\n",
    "    new code. Prefer loading images with\n",
    "    `tf.keras.utils.image_dataset_from_directory` and transforming the output\n",
    "    `tf.data.Dataset` with preprocessing layers. For more information, see the\n",
    "    tutorials for [loading images](\n",
    "    https://www.tensorflow.org/tutorials/load_data/images) and\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n",
    "    method.\n",
    "\n",
    "    Args:\n",
    "        n: Integer, total number of samples in the dataset to loop over.\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seeding for data shuffling.\n",
    "    \"\"\"\n",
    "\n",
    "    white_list_formats = (\"png\", \"jpg\", \"jpeg\", \"bmp\", \"ppm\", \"tif\", \"tiff\")\n",
    "\n",
    "    def __init__(self, n, batch_size, shuffle, seed):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_index = 0\n",
    "        self.total_batches_seen = 0\n",
    "        self.lock = threading.Lock()\n",
    "        self.index_array = None\n",
    "        self.index_generator = self._flow_index()\n",
    "\n",
    "    def _set_index_array(self):\n",
    "        self.index_array = np.arange(self.n)\n",
    "        if self.shuffle:\n",
    "            self.index_array = np.random.permutation(self.n)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError(\n",
    "                \"Asked to retrieve element {idx}, \"\n",
    "                \"but the Sequence \"\n",
    "                \"has length {length}\".format(idx=idx, length=len(self))\n",
    "            )\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed + self.total_batches_seen)\n",
    "        self.total_batches_seen += 1\n",
    "        if self.index_array is None:\n",
    "            self._set_index_array()\n",
    "        index_array = self.index_array[\n",
    "            self.batch_size * idx : self.batch_size * (idx + 1)\n",
    "        ]\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size  # round up\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._set_index_array()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def _flow_index(self):\n",
    "        # Ensure self.batch_index is 0.\n",
    "        self.reset()\n",
    "        while 1:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed + self.total_batches_seen)\n",
    "            if self.batch_index == 0:\n",
    "                self._set_index_array()\n",
    "\n",
    "            if self.n == 0:\n",
    "                # Avoiding modulo by zero error\n",
    "                current_index = 0\n",
    "            else:\n",
    "                current_index = (self.batch_index * self.batch_size) % self.n\n",
    "            if self.n > current_index + self.batch_size:\n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                self.batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "            yield self.index_array[\n",
    "                current_index : current_index + self.batch_size\n",
    "            ]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Needed if we want to do something like:\n",
    "        # for x, y in data_gen.flow(...):\n",
    "        return self\n",
    "\n",
    "    def __next__(self, *args, **kwargs):\n",
    "        return self.next(*args, **kwargs)\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        Returns:\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"Gets a batch of transformed samples.\n",
    "\n",
    "        Args:\n",
    "            index_array: Array of sample indices to include in batch.\n",
    "        Returns:\n",
    "            A batch of transformed samples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def _iter_valid_files(directory, white_list_formats, follow_links):\n",
    "    \"\"\"Iterates on files with extension.\n",
    "\n",
    "    Args:\n",
    "        directory: Absolute path to the directory\n",
    "            containing files to be counted\n",
    "        white_list_formats: Set of strings containing allowed extensions for\n",
    "            the files to be counted.\n",
    "        follow_links: Boolean, follow symbolic links to subdirectories.\n",
    "    Yields:\n",
    "        Tuple of (root, filename) with extension in `white_list_formats`.\n",
    "    \"\"\"\n",
    "\n",
    "    def _recursive_list(subpath):\n",
    "        return sorted(\n",
    "            os.walk(subpath, followlinks=follow_links), key=lambda x: x[0]\n",
    "        )\n",
    "\n",
    "    for root, _, files in _recursive_list(directory):\n",
    "        for fname in sorted(files):\n",
    "            if fname.lower().endswith(\".tiff\"):\n",
    "                warnings.warn(\n",
    "                    'Using \".tiff\" files with multiple bands '\n",
    "                    \"will cause distortion. Please verify your output.\"\n",
    "                )\n",
    "            if fname.lower().endswith(white_list_formats):\n",
    "                yield root, fname\n",
    "\n",
    "\n",
    "def _list_valid_filenames_in_directory(\n",
    "    directory, white_list_formats, split, class_indices, follow_links\n",
    "):\n",
    "    \"\"\"Lists paths of files in `subdir` with extensions in `white_list_formats`.\n",
    "\n",
    "    Args:\n",
    "        directory: absolute path to a directory containing the files to list.\n",
    "            The directory name is used as class label\n",
    "            and must be a key of `class_indices`.\n",
    "        white_list_formats: set of strings containing allowed extensions for\n",
    "            the files to be counted.\n",
    "        split: tuple of floats (e.g. `(0.2, 0.6)`) to only take into\n",
    "            account a certain fraction of files in each directory.\n",
    "            E.g.: `segment=(0.6, 1.0)` would only account for last 40 percent\n",
    "            of images in each directory.\n",
    "        class_indices: dictionary mapping a class name to its index.\n",
    "        follow_links: boolean, follow symbolic links to subdirectories.\n",
    "\n",
    "    Returns:\n",
    "         classes: a list of class indices\n",
    "         filenames: the path of valid files in `directory`, relative from\n",
    "             `directory`'s parent (e.g., if `directory` is \"dataset/class1\",\n",
    "            the filenames will be\n",
    "            `[\"class1/file1.jpg\", \"class1/file2.jpg\", ...]`).\n",
    "    \"\"\"\n",
    "    dirname = os.path.basename(directory)\n",
    "    if split:\n",
    "        all_files = list(\n",
    "            _iter_valid_files(directory, white_list_formats, follow_links)\n",
    "        )\n",
    "        num_files = len(all_files)\n",
    "        start, stop = int(split[0] * num_files), int(split[1] * num_files)\n",
    "        valid_files = all_files[start:stop]\n",
    "    else:\n",
    "        valid_files = _iter_valid_files(\n",
    "            directory, white_list_formats, follow_links\n",
    "        )\n",
    "    classes = []\n",
    "    filenames = []\n",
    "    for root, fname in valid_files:\n",
    "        classes.append(class_indices[dirname])\n",
    "        absolute_path = os.path.join(root, fname)\n",
    "        relative_path = os.path.join(\n",
    "            dirname, os.path.relpath(absolute_path, directory)\n",
    "        )\n",
    "        filenames.append(relative_path)\n",
    "\n",
    "    return classes, filenames\n",
    "\n",
    "\n",
    "class BatchFromFilesMixin:\n",
    "    \"\"\"Adds methods related to getting batches from filenames.\n",
    "\n",
    "    It includes the logic to transform image files to batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def set_processing_attrs(\n",
    "        self,\n",
    "        image_data_generator,\n",
    "        target_size,\n",
    "        color_mode,\n",
    "        data_format,\n",
    "        save_to_dir,\n",
    "        save_prefix,\n",
    "        save_format,\n",
    "        subset,\n",
    "        interpolation,\n",
    "        keep_aspect_ratio,\n",
    "    ):\n",
    "        \"\"\"Sets attributes to use later for processing files into a batch.\n",
    "\n",
    "        Args:\n",
    "            image_data_generator: Instance of `ImageDataGenerator`\n",
    "                to use for random transformations and normalization.\n",
    "            target_size: tuple of integers, dimensions to resize input images\n",
    "            to.\n",
    "            color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n",
    "                Color mode to read images.\n",
    "            data_format: String, one of `channels_first`, `channels_last`.\n",
    "            save_to_dir: Optional directory where to save the pictures\n",
    "                being yielded, in a viewable format. This is useful\n",
    "                for visualizing the random transformations being\n",
    "                applied, for debugging purposes.\n",
    "            save_prefix: String prefix to use for saving sample\n",
    "                images (if `save_to_dir` is set).\n",
    "            save_format: Format to use for saving sample images\n",
    "                (if `save_to_dir` is set).\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "                validation_split is set in ImageDataGenerator.\n",
    "            interpolation: Interpolation method used to resample the image if\n",
    "                the target size is different from that of the loaded image.\n",
    "                Supported methods are \"nearest\", \"bilinear\", and \"bicubic\". If\n",
    "                PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "                supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "                \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "            keep_aspect_ratio: Boolean, whether to resize images to a target\n",
    "                size without aspect ratio distortion. The image is cropped in\n",
    "                the center with target aspect ratio before resizing.\n",
    "        \"\"\"\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.keep_aspect_ratio = keep_aspect_ratio\n",
    "        if color_mode not in {\"rgb\", \"rgba\", \"grayscale\"}:\n",
    "            raise ValueError(\n",
    "                \"Invalid color mode:\",\n",
    "                color_mode,\n",
    "                '; expected \"rgb\", \"rgba\", or \"grayscale\".',\n",
    "            )\n",
    "        self.color_mode = color_mode\n",
    "        self.data_format = data_format\n",
    "        if self.color_mode == \"rgba\":\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (4,)\n",
    "            else:\n",
    "                self.image_shape = (4,) + self.target_size\n",
    "        elif self.color_mode == \"rgb\":\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (3,)\n",
    "            else:\n",
    "                self.image_shape = (3,) + self.target_size\n",
    "        else:\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (1,)\n",
    "            else:\n",
    "                self.image_shape = (1,) + self.target_size\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        self.interpolation = interpolation\n",
    "        if subset is not None:\n",
    "            validation_split = self.image_data_generator._validation_split\n",
    "            if subset == \"validation\":\n",
    "                split = (0, validation_split)\n",
    "            elif subset == \"training\":\n",
    "                split = (validation_split, 1)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Invalid subset name: %s;\"\n",
    "                    'expected \"training\" or \"validation\"' % (subset,)\n",
    "                )\n",
    "        else:\n",
    "            split = None\n",
    "        self.split = split\n",
    "        self.subset = subset\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"Gets a batch of transformed samples.\n",
    "\n",
    "        Args:\n",
    "            index_array: Array of sample indices to include in batch.\n",
    "        Returns:\n",
    "            A batch of transformed samples.\n",
    "        \"\"\"\n",
    "        batch_x = np.zeros(\n",
    "            (len(index_array),) + self.image_shape, dtype=self.dtype\n",
    "        )\n",
    "        # build batch of image data\n",
    "        # self.filepaths is dynamic, is better to call it once outside the loop\n",
    "        filepaths = self.filepaths\n",
    "        for i, j in enumerate(index_array):\n",
    "            img = image_utils.load_img(\n",
    "                filepaths[j],\n",
    "                color_mode=self.color_mode,\n",
    "                target_size=self.target_size,\n",
    "                interpolation=self.interpolation,\n",
    "                keep_aspect_ratio=self.keep_aspect_ratio,\n",
    "            )\n",
    "            x = image_utils.img_to_array(img, data_format=self.data_format)\n",
    "            # Pillow images should be closed after `load_img`,\n",
    "            # but not PIL images.\n",
    "            if hasattr(img, \"close\"):\n",
    "                img.close()\n",
    "            if self.image_data_generator:\n",
    "                params = self.image_data_generator.get_random_transform(x.shape)\n",
    "                x = self.image_data_generator.apply_transform(x, params)\n",
    "                x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        # optionally save augmented images to disk for debugging purposes\n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = image_utils.array_to_img(\n",
    "                    batch_x[i], self.data_format, scale=True\n",
    "                )\n",
    "                fname = \"{prefix}_{index}_{hash}.{format}\".format(\n",
    "                    prefix=self.save_prefix,\n",
    "                    index=j,\n",
    "                    hash=np.random.randint(1e7),\n",
    "                    format=self.save_format,\n",
    "                )\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        # build batch of labels\n",
    "        if self.class_mode == \"input\":\n",
    "            batch_y = batch_x.copy()\n",
    "        elif self.class_mode in {\"binary\", \"sparse\"}:\n",
    "            batch_y = np.empty(len(batch_x), dtype=self.dtype)\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i] = self.classes[n_observation]\n",
    "        elif self.class_mode == \"categorical\":\n",
    "            batch_y = np.zeros(\n",
    "                (len(batch_x), len(self.class_indices)), dtype=self.dtype\n",
    "            )\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i, self.classes[n_observation]] = 1.0\n",
    "        elif self.class_mode == \"multi_output\":\n",
    "            batch_y = [output[index_array] for output in self.labels]\n",
    "        elif self.class_mode == \"raw\":\n",
    "            batch_y = self.labels[index_array]\n",
    "        else:\n",
    "            return batch_x\n",
    "        if self.sample_weight is None:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x, batch_y, self.sample_weight[index_array]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        \"\"\"List of absolute paths to image files.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"`filepaths` property method has not \"\n",
    "            \"been implemented in {}.\".format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"Class labels of every observation.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"`labels` property method has not been implemented in {}.\".format(\n",
    "                type(self).__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        raise NotImplementedError(\n",
    "            \"`sample_weight` property method has not \"\n",
    "            \"been implemented in {}.\".format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.DirectoryIterator\")\n",
    "class DirectoryIterator(BatchFromFilesMixin, Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.DirectoryIterator` is not\n",
    "    recommended for new code. Prefer loading images with\n",
    "    `tf.keras.utils.image_dataset_from_directory` and transforming the output\n",
    "    `tf.data.Dataset` with preprocessing layers. For more information, see the\n",
    "    tutorials for [loading images](\n",
    "    https://www.tensorflow.org/tutorials/load_data/images) and\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        directory: Path to the directory to read images from. Each subdirectory\n",
    "          in this directory will be considered to contain images from one class,\n",
    "          or alternatively you could specify class subdirectories via the\n",
    "          `classes` argument.\n",
    "        image_data_generator: Instance of `ImageDataGenerator` to use for random\n",
    "          transformations and normalization.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`. Color mode to read\n",
    "          images.\n",
    "        classes: Optional list of strings, names of subdirectories containing\n",
    "          images from each class (e.g. `[\"dogs\", \"cats\"]`). It will be computed\n",
    "          automatically if not set.\n",
    "        class_mode: Mode for yielding the targets:\n",
    "            - `\"binary\"`: binary targets (if there are only two classes),\n",
    "            - `\"categorical\"`: categorical targets,\n",
    "            - `\"sparse\"`: integer targets,\n",
    "            - `\"input\"`: targets are images identical to input images (mainly\n",
    "              used to work with autoencoders),\n",
    "            - `None`: no targets get yielded (only input images are yielded).\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures being\n",
    "          yielded, in a viewable format. This is useful for visualizing the\n",
    "          random transformations being applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample images (if\n",
    "          `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images (if `save_to_dir` is\n",
    "          set).\n",
    "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "          validation_split is set in ImageDataGenerator.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "          target size is different from that of the loaded image. Supported\n",
    "          methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n",
    "          or newer is installed, \"lanczos\" is also supported. If PIL version\n",
    "          3.4.0 or newer is installed, \"box\" and \"hamming\" are also supported.\n",
    "          By default, \"nearest\" is used.\n",
    "        keep_aspect_ratio: Boolean, whether to resize images to a target size\n",
    "            without aspect ratio distortion. The image is cropped in the center\n",
    "            with target aspect ratio before resizing.\n",
    "        dtype: Dtype to use for generated arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    allowed_class_modes = {\"categorical\", \"binary\", \"sparse\", \"input\", None}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory,\n",
    "        image_data_generator,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        data_format=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        follow_links=False,\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "        super().set_processing_attrs(\n",
    "            image_data_generator,\n",
    "            target_size,\n",
    "            color_mode,\n",
    "            data_format,\n",
    "            save_to_dir,\n",
    "            save_prefix,\n",
    "            save_format,\n",
    "            subset,\n",
    "            interpolation,\n",
    "            keep_aspect_ratio,\n",
    "        )\n",
    "        self.directory = directory\n",
    "        self.classes = classes\n",
    "        if class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError(\n",
    "                \"Invalid class_mode: {}; expected one of: {}\".format(\n",
    "                    class_mode, self.allowed_class_modes\n",
    "                )\n",
    "            )\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # First, count the number of samples and classes.\n",
    "        self.samples = 0\n",
    "\n",
    "        if not classes:\n",
    "            classes = []\n",
    "            for subdir in sorted(os.listdir(directory)):\n",
    "                if os.path.isdir(os.path.join(directory, subdir)):\n",
    "                    classes.append(subdir)\n",
    "        self.num_classes = len(classes)\n",
    "        self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "\n",
    "        pool = multiprocessing.pool.ThreadPool()\n",
    "\n",
    "        # Second, build an index of the images\n",
    "        # in the different class subfolders.\n",
    "        results = []\n",
    "        self.filenames = []\n",
    "        i = 0\n",
    "        for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n",
    "            results.append(\n",
    "                pool.apply_async(\n",
    "                    _list_valid_filenames_in_directory,\n",
    "                    (\n",
    "                        dirpath,\n",
    "                        self.white_list_formats,\n",
    "                        self.split,\n",
    "                        self.class_indices,\n",
    "                        follow_links,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        classes_list = []\n",
    "        for res in results:\n",
    "            classes, filenames = res.get()\n",
    "            classes_list.append(classes)\n",
    "            self.filenames += filenames\n",
    "        self.samples = len(self.filenames)\n",
    "        self.classes = np.zeros((self.samples,), dtype=\"int32\")\n",
    "        for classes in classes_list:\n",
    "            self.classes[i : i + len(classes)] = classes\n",
    "            i += len(classes)\n",
    "\n",
    "        io_utils.print_msg(\n",
    "            f\"Found {self.samples} images belonging to \"\n",
    "            f\"{self.num_classes} classes.\"\n",
    "        )\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super().__init__(self.samples, batch_size, shuffle, seed)\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.classes\n",
    "\n",
    "    @property  # mixin needs this property to work\n",
    "    def sample_weight(self):\n",
    "        # no sample weights will be returned\n",
    "        return None\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.NumpyArrayIterator\")\n",
    "class NumpyArrayIterator(Iterator):\n",
    "    \"\"\"Iterator yielding data from a Numpy array.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.NumpyArrayIterator` is not\n",
    "    recommended for new code. Prefer loading images with\n",
    "    `tf.keras.utils.image_dataset_from_directory` and transforming the output\n",
    "    `tf.data.Dataset` with preprocessing layers. For more information, see the\n",
    "    tutorials for [loading images](\n",
    "    https://www.tensorflow.org/tutorials/load_data/images) and\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        x: Numpy array of input data or tuple. If tuple, the second elements is\n",
    "          either another numpy array or a list of numpy arrays, each of which\n",
    "          gets passed through as an output without any modifications.\n",
    "        y: Numpy array of targets data.\n",
    "        image_data_generator: Instance of `ImageDataGenerator` to use for random\n",
    "          transformations and normalization.\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        sample_weight: Numpy array of sample weights.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures being\n",
    "          yielded, in a viewable format. This is useful for visualizing the\n",
    "          random transformations being applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample images (if\n",
    "          `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images (if `save_to_dir` is\n",
    "          set).\n",
    "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "          validation_split is set in ImageDataGenerator.\n",
    "        ignore_class_split: Boolean (default: False), ignore difference\n",
    "          in number of classes in labels across train and validation\n",
    "          split (useful for non-classification tasks)\n",
    "        dtype: Dtype to use for the generated arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        image_data_generator,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        data_format=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        ignore_class_split=False,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "        self.dtype = dtype\n",
    "        if isinstance(x, tuple) or isinstance(x, list):\n",
    "            if not isinstance(x[1], list):\n",
    "                x_misc = [np.asarray(x[1])]\n",
    "            else:\n",
    "                x_misc = [np.asarray(xx) for xx in x[1]]\n",
    "            x = x[0]\n",
    "            for xx in x_misc:\n",
    "                if len(x) != len(xx):\n",
    "                    raise ValueError(\n",
    "                        \"All of the arrays in `x` \"\n",
    "                        \"should have the same length. \"\n",
    "                        \"Found a pair with: len(x[0]) = %s, len(x[?]) = %s\"\n",
    "                        % (len(x), len(xx))\n",
    "                    )\n",
    "        else:\n",
    "            x_misc = []\n",
    "\n",
    "        if y is not None and len(x) != len(y):\n",
    "            raise ValueError(\n",
    "                \"`x` (images tensor) and `y` (labels) \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, y.shape = %s\"\n",
    "                % (np.asarray(x).shape, np.asarray(y).shape)\n",
    "            )\n",
    "        if sample_weight is not None and len(x) != len(sample_weight):\n",
    "            raise ValueError(\n",
    "                \"`x` (images tensor) and `sample_weight` \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, sample_weight.shape = %s\"\n",
    "                % (np.asarray(x).shape, np.asarray(sample_weight).shape)\n",
    "            )\n",
    "        if subset is not None:\n",
    "            if subset not in {\"training\", \"validation\"}:\n",
    "                raise ValueError(\n",
    "                    \"Invalid subset name:\",\n",
    "                    subset,\n",
    "                    '; expected \"training\" or \"validation\".',\n",
    "                )\n",
    "            split_idx = int(len(x) * image_data_generator._validation_split)\n",
    "\n",
    "            if (\n",
    "                y is not None\n",
    "                and not ignore_class_split\n",
    "                and not np.array_equal(\n",
    "                    np.unique(y[:split_idx]), np.unique(y[split_idx:])\n",
    "                )\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Training and validation subsets \"\n",
    "                    \"have different number of classes after \"\n",
    "                    \"the split. If your numpy arrays are \"\n",
    "                    \"sorted by the label, you might want \"\n",
    "                    \"to shuffle them.\"\n",
    "                )\n",
    "\n",
    "            if subset == \"validation\":\n",
    "                x = x[:split_idx]\n",
    "                x_misc = [np.asarray(xx[:split_idx]) for xx in x_misc]\n",
    "                if y is not None:\n",
    "                    y = y[:split_idx]\n",
    "            else:\n",
    "                x = x[split_idx:]\n",
    "                x_misc = [np.asarray(xx[split_idx:]) for xx in x_misc]\n",
    "                if y is not None:\n",
    "                    y = y[split_idx:]\n",
    "\n",
    "        self.x = np.asarray(x, dtype=self.dtype)\n",
    "        self.x_misc = x_misc\n",
    "        if self.x.ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input data in `NumpyArrayIterator` \"\n",
    "                \"should have rank 4. You passed an array \"\n",
    "                \"with shape\",\n",
    "                self.x.shape,\n",
    "            )\n",
    "        channels_axis = 3 if data_format == \"channels_last\" else 1\n",
    "        if self.x.shape[channels_axis] not in {1, 3, 4}:\n",
    "            warnings.warn(\n",
    "                \"NumpyArrayIterator is set to use the \"\n",
    "                'data format convention \"' + data_format + '\" '\n",
    "                \"(channels on axis \"\n",
    "                + str(channels_axis)\n",
    "                + \"), i.e. expected either 1, 3, or 4 \"\n",
    "                \"channels on axis \" + str(channels_axis) + \". \"\n",
    "                \"However, it was passed an array with shape \"\n",
    "                + str(self.x.shape)\n",
    "                + \" (\"\n",
    "                + str(self.x.shape[channels_axis])\n",
    "                + \" channels).\"\n",
    "            )\n",
    "        if y is not None:\n",
    "            self.y = np.asarray(y)\n",
    "        else:\n",
    "            self.y = None\n",
    "        if sample_weight is not None:\n",
    "            self.sample_weight = np.asarray(sample_weight)\n",
    "        else:\n",
    "            self.sample_weight = None\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.data_format = data_format\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        super().__init__(x.shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros(\n",
    "            tuple([len(index_array)] + list(self.x.shape)[1:]), dtype=self.dtype\n",
    "        )\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = self.x[j]\n",
    "            params = self.image_data_generator.get_random_transform(x.shape)\n",
    "            x = self.image_data_generator.apply_transform(\n",
    "                x.astype(self.dtype), params\n",
    "            )\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = image_utils.array_to_img(\n",
    "                    batch_x[i], self.data_format, scale=True\n",
    "                )\n",
    "                fname = \"{prefix}_{index}_{hash}.{format}\".format(\n",
    "                    prefix=self.save_prefix,\n",
    "                    index=j,\n",
    "                    hash=np.random.randint(1e4),\n",
    "                    format=self.save_format,\n",
    "                )\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "        output = (batch_x if not batch_x_miscs else [batch_x] + batch_x_miscs,)\n",
    "        if self.y is None:\n",
    "            return output[0]\n",
    "        output += (self.y[index_array],)\n",
    "        if self.sample_weight is not None:\n",
    "            output += (self.sample_weight[index_array],)\n",
    "        return output\n",
    "\n",
    "\n",
    "def validate_filename(filename, white_list_formats):\n",
    "    \"\"\"Check if a filename refers to a valid file.\n",
    "\n",
    "    Args:\n",
    "        filename: String, absolute path to a file\n",
    "        white_list_formats: Set, allowed file extensions\n",
    "    Returns:\n",
    "        A boolean value indicating if the filename is valid or not\n",
    "    \"\"\"\n",
    "    return filename.lower().endswith(white_list_formats) and os.path.isfile(\n",
    "        filename\n",
    "    )\n",
    "\n",
    "\n",
    "class DataFrameIterator(BatchFromFilesMixin, Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk as a dataframe.\n",
    "\n",
    "    Args:\n",
    "        dataframe: Pandas dataframe containing the filepaths relative to\n",
    "          `directory` (or absolute paths if `directory` is None) of the images\n",
    "          in a string column. It should include other column/s depending on the\n",
    "          `class_mode`: - if `class_mode` is `\"categorical\"` (default value) it\n",
    "          must include the `y_col` column with the class/es of each image.\n",
    "          Values in column can be string/list/tuple if a single class or\n",
    "          list/tuple if multiple classes.\n",
    "            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include the\n",
    "              given `y_col` column with class values as strings.\n",
    "            - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n",
    "              the columns specified in `y_col`.\n",
    "            - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n",
    "        directory: string, path to the directory to read images from. If `None`,\n",
    "          data in `x_col` column should be absolute paths.\n",
    "        image_data_generator: Instance of `ImageDataGenerator` to use for random\n",
    "          transformations and normalization. If None, no transformations and\n",
    "          normalizations are made.\n",
    "        x_col: string, column in `dataframe` that contains the filenames (or\n",
    "          absolute paths if `directory` is `None`).\n",
    "        y_col: string or list, column/s in `dataframe` that has the target data.\n",
    "        weight_col: string, column in `dataframe` that contains the sample\n",
    "            weights. Default: `None`.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`. Color mode to read\n",
    "          images.\n",
    "        classes: Optional list of strings, classes to use (e.g. `[\"dogs\",\n",
    "          \"cats\"]`). If None, all classes in `y_col` will be used.\n",
    "        class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
    "          \"raw\", \"sparse\" or None. Default: \"categorical\".\n",
    "          Mode for yielding the targets:\n",
    "            - `\"binary\"`: 1D numpy array of binary labels,\n",
    "            - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n",
    "              Supports multi-label output.\n",
    "            - `\"input\"`: images identical to input images (mainly used to work\n",
    "              with autoencoders),\n",
    "            - `\"multi_output\"`: list with the values of the different columns,\n",
    "            - `\"raw\"`: numpy array of values in `y_col` column(s),\n",
    "            - `\"sparse\"`: 1D numpy array of integer labels, - `None`, no targets\n",
    "              are returned (the generator will only yield batches of image data,\n",
    "              which is useful to use in `model.predict()`).\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures being\n",
    "          yielded, in a viewable format. This is useful for visualizing the\n",
    "          random transformations being applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample images (if\n",
    "          `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images (if `save_to_dir` is\n",
    "          set).\n",
    "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "          validation_split is set in ImageDataGenerator.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "          target size is different from that of the loaded image. Supported\n",
    "          methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n",
    "          or newer is installed, \"lanczos\" is also supported. If PIL version\n",
    "          3.4.0 or newer is installed, \"box\" and \"hamming\" are also supported.\n",
    "          By default, \"nearest\" is used.\n",
    "        keep_aspect_ratio: Boolean, whether to resize images to a target size\n",
    "          without aspect ratio distortion. The image is cropped in the center\n",
    "          with target aspect ratio before resizing.\n",
    "        dtype: Dtype to use for the generated arrays.\n",
    "        validate_filenames: Boolean, whether to validate image filenames in\n",
    "          `x_col`. If `True`, invalid images will be ignored. Disabling this\n",
    "          option can lead to speed-up in the instantiation of this class.\n",
    "          Default: `True`.\n",
    "    \"\"\"\n",
    "\n",
    "    allowed_class_modes = {\n",
    "        \"binary\",\n",
    "        \"categorical\",\n",
    "        \"input\",\n",
    "        \"multi_output\",\n",
    "        \"raw\",\n",
    "        \"sparse\",\n",
    "        None,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        directory=None,\n",
    "        image_data_generator=None,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        weight_col=None,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        data_format=\"channels_last\",\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "        dtype=\"float32\",\n",
    "        validate_filenames=True,\n",
    "    ):\n",
    "        super().set_processing_attrs(\n",
    "            image_data_generator,\n",
    "            target_size,\n",
    "            color_mode,\n",
    "            data_format,\n",
    "            save_to_dir,\n",
    "            save_prefix,\n",
    "            save_format,\n",
    "            subset,\n",
    "            interpolation,\n",
    "            keep_aspect_ratio,\n",
    "        )\n",
    "        df = dataframe.copy()\n",
    "        self.directory = directory or \"\"\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # check that inputs match the required class_mode\n",
    "        self._check_params(df, x_col, y_col, weight_col, classes)\n",
    "        if (\n",
    "            validate_filenames\n",
    "        ):  # check which image files are valid and keep them\n",
    "            df = self._filter_valid_filepaths(df, x_col)\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            df, classes = self._filter_classes(df, y_col, classes)\n",
    "            num_classes = len(classes)\n",
    "            # build an index of all the unique classes\n",
    "            self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "        # retrieve only training or validation set\n",
    "        if self.split:\n",
    "            num_files = len(df)\n",
    "            start = int(self.split[0] * num_files)\n",
    "            stop = int(self.split[1] * num_files)\n",
    "            df = df.iloc[start:stop, :]\n",
    "        # get labels for each observation\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            self.classes = self.get_classes(df, y_col)\n",
    "        self.filenames = df[x_col].tolist()\n",
    "        self._sample_weight = df[weight_col].values if weight_col else None\n",
    "\n",
    "        if class_mode == \"multi_output\":\n",
    "            self._targets = [np.array(df[col].tolist()) for col in y_col]\n",
    "        if class_mode == \"raw\":\n",
    "            self._targets = df[y_col].values\n",
    "        self.samples = len(self.filenames)\n",
    "        validated_string = (\n",
    "            \"validated\" if validate_filenames else \"non-validated\"\n",
    "        )\n",
    "        if class_mode in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            io_utils.print_msg(\n",
    "                f\"Found {self.samples} {validated_string} image filenames.\"\n",
    "            )\n",
    "        else:\n",
    "            io_utils.print_msg(\n",
    "                f\"Found {self.samples} {validated_string} image filenames \"\n",
    "                f\"belonging to {num_classes} classes.\"\n",
    "            )\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super().__init__(self.samples, batch_size, shuffle, seed)\n",
    "\n",
    "    def _check_params(self, df, x_col, y_col, weight_col, classes):\n",
    "        # check class mode is one of the currently supported\n",
    "        if self.class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError(\n",
    "                \"Invalid class_mode: {}; expected one of: {}\".format(\n",
    "                    self.class_mode, self.allowed_class_modes\n",
    "                )\n",
    "            )\n",
    "        # check that y_col has several column names if class_mode is\n",
    "        # multi_output\n",
    "        if (self.class_mode == \"multi_output\") and not isinstance(y_col, list):\n",
    "            raise TypeError(\n",
    "                'If class_mode=\"{}\", y_col must be a list. Received {}.'.format(\n",
    "                    self.class_mode, type(y_col).__name__\n",
    "                )\n",
    "            )\n",
    "        # check that filenames/filepaths column values are all strings\n",
    "        if not all(df[x_col].apply(lambda x: isinstance(x, str))):\n",
    "            raise TypeError(\n",
    "                \"All values in column x_col={} must be strings.\".format(x_col)\n",
    "            )\n",
    "        # check labels are string if class_mode is binary or sparse\n",
    "        if self.class_mode in {\"binary\", \"sparse\"}:\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, str))):\n",
    "                raise TypeError(\n",
    "                    'If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                    \"values must be strings.\".format(self.class_mode, y_col)\n",
    "                )\n",
    "        # check that if binary there are only 2 different classes\n",
    "        if self.class_mode == \"binary\":\n",
    "            if classes:\n",
    "                classes = set(classes)\n",
    "                if len(classes) != 2:\n",
    "                    raise ValueError(\n",
    "                        'If class_mode=\"binary\" there must be 2 '\n",
    "                        \"classes. {} class/es were given.\".format(len(classes))\n",
    "                    )\n",
    "            elif df[y_col].nunique() != 2:\n",
    "                raise ValueError(\n",
    "                    'If class_mode=\"binary\" there must be 2 classes. '\n",
    "                    \"Found {} classes.\".format(df[y_col].nunique())\n",
    "                )\n",
    "        # check values are string, list or tuple if class_mode is categorical\n",
    "        if self.class_mode == \"categorical\":\n",
    "            types = (str, list, tuple)\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, types))):\n",
    "                raise TypeError(\n",
    "                    'If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                    \"values must be type string, list or tuple.\".format(\n",
    "                        self.class_mode, y_col\n",
    "                    )\n",
    "                )\n",
    "        # raise warning if classes are given but will be unused\n",
    "        if classes and self.class_mode in {\n",
    "            \"input\",\n",
    "            \"multi_output\",\n",
    "            \"raw\",\n",
    "            None,\n",
    "        }:\n",
    "            warnings.warn(\n",
    "                '`classes` will be ignored given the class_mode=\"{}\"'.format(\n",
    "                    self.class_mode\n",
    "                )\n",
    "            )\n",
    "        # check that if weight column that the values are numerical\n",
    "        if weight_col and not issubclass(df[weight_col].dtype.type, np.number):\n",
    "            raise TypeError(\n",
    "                \"Column weight_col={} must be numeric.\".format(weight_col)\n",
    "            )\n",
    "\n",
    "    def get_classes(self, df, y_col):\n",
    "        labels = []\n",
    "        for label in df[y_col]:\n",
    "            if isinstance(label, (list, tuple)):\n",
    "                labels.append([self.class_indices[lbl] for lbl in label])\n",
    "            else:\n",
    "                labels.append(self.class_indices[label])\n",
    "        return labels\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_classes(df, y_col, classes):\n",
    "        df = df.copy()\n",
    "\n",
    "        def remove_classes(labels, classes):\n",
    "            if isinstance(labels, (list, tuple)):\n",
    "                labels = [cls for cls in labels if cls in classes]\n",
    "                return labels or None\n",
    "            elif isinstance(labels, str):\n",
    "                return labels if labels in classes else None\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Expect string, list or tuple \"\n",
    "                    \"but found {} in {} column \".format(type(labels), y_col)\n",
    "                )\n",
    "\n",
    "        if classes:\n",
    "            # prepare for membership lookup\n",
    "            classes = list(collections.OrderedDict.fromkeys(classes).keys())\n",
    "            df[y_col] = df[y_col].apply(lambda x: remove_classes(x, classes))\n",
    "        else:\n",
    "            classes = set()\n",
    "            for v in df[y_col]:\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    classes.update(v)\n",
    "                else:\n",
    "                    classes.add(v)\n",
    "            classes = sorted(classes)\n",
    "        return df.dropna(subset=[y_col]), classes\n",
    "\n",
    "    def _filter_valid_filepaths(self, df, x_col):\n",
    "        \"\"\"Keep only dataframe rows with valid filenames.\n",
    "\n",
    "        Args:\n",
    "            df: Pandas dataframe containing filenames in a column\n",
    "            x_col: string, column in `df` that contains the filenames or\n",
    "                filepaths\n",
    "        Returns:\n",
    "            absolute paths to image files\n",
    "        \"\"\"\n",
    "        filepaths = df[x_col].map(\n",
    "            lambda fname: os.path.join(self.directory, fname)\n",
    "        )\n",
    "        mask = filepaths.apply(\n",
    "            validate_filename, args=(self.white_list_formats,)\n",
    "        )\n",
    "        n_invalid = (~mask).sum()\n",
    "        if n_invalid:\n",
    "            warnings.warn(\n",
    "                'Found {} invalid image filename(s) in x_col=\"{}\". '\n",
    "                \"These filename(s) will be ignored.\".format(n_invalid, x_col)\n",
    "            )\n",
    "        return df[mask]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self.class_mode in {\"multi_output\", \"raw\"}:\n",
    "            return self._targets\n",
    "        else:\n",
    "            return self.classes\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        return self._sample_weight\n",
    "\n",
    "\n",
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.ImageDataGenerator\")\n",
    "class ImageDataGenerator:\n",
    "    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.ImageDataGenerator` is not\n",
    "    recommended for new code. Prefer loading images with\n",
    "    `tf.keras.utils.image_dataset_from_directory` and transforming the output\n",
    "    `tf.data.Dataset` with preprocessing layers. For more information, see the\n",
    "    tutorials for [loading images](\n",
    "    https://www.tensorflow.org/tutorials/load_data/images) and\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "     The data will be looped over (in batches).\n",
    "\n",
    "    Args:\n",
    "        featurewise_center: Boolean. Set input mean to 0 over the dataset,\n",
    "          feature-wise.\n",
    "        samplewise_center: Boolean. Set each sample mean to 0.\n",
    "        featurewise_std_normalization: Boolean. Divide inputs by std of the\n",
    "          dataset, feature-wise.\n",
    "        samplewise_std_normalization: Boolean. Divide each input by its std.\n",
    "        zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
    "        zca_whitening: Boolean. Apply ZCA whitening.\n",
    "        rotation_range: Int. Degree range for random rotations.\n",
    "        width_shift_range: Float, 1-D array-like or int\n",
    "            - float: fraction of total width, if < 1, or pixels if >= 1.\n",
    "            - 1-D array-like: random elements from the array.\n",
    "            - int: integer number of pixels from interval `(-width_shift_range,\n",
    "              +width_shift_range)` - With `width_shift_range=2` possible values\n",
    "              are integers `[-1, 0, +1]`, same as with `width_shift_range=[-1,\n",
    "              0, +1]`, while with `width_shift_range=1.0` possible values are\n",
    "              floats in the interval [-1.0, +1.0).\n",
    "        height_shift_range: Float, 1-D array-like or int\n",
    "            - float: fraction of total height, if < 1, or pixels if >= 1.\n",
    "            - 1-D array-like: random elements from the array.\n",
    "            - int: integer number of pixels from interval `(-height_shift_range,\n",
    "              +height_shift_range)` - With `height_shift_range=2` possible\n",
    "              values are integers `[-1, 0, +1]`, same as with\n",
    "              `height_shift_range=[-1, 0, +1]`, while with\n",
    "              `height_shift_range=1.0` possible values are floats in the\n",
    "              interval [-1.0, +1.0).\n",
    "        brightness_range: Tuple or list of two floats. Range for picking a\n",
    "          brightness shift value from.\n",
    "        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise\n",
    "          direction in degrees)\n",
    "        zoom_range: Float or [lower, upper]. Range for random zoom. If a float,\n",
    "          `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n",
    "        channel_shift_range: Float. Range for random channel shifts.\n",
    "        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default\n",
    "          is 'nearest'. Points outside the boundaries of the input are filled\n",
    "          according to the given mode:\n",
    "            - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n",
    "            - 'nearest':  aaaaaaaa|abcd|dddddddd\n",
    "            - 'reflect':  abcddcba|abcd|dcbaabcd\n",
    "            - 'wrap':  abcdabcd|abcd|abcdabcd\n",
    "        cval: Float or Int. Value used for points outside the boundaries when\n",
    "          `fill_mode = \"constant\"`.\n",
    "        horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
    "        vertical_flip: Boolean. Randomly flip inputs vertically.\n",
    "        rescale: rescaling factor. Defaults to None. If None or 0, no rescaling\n",
    "          is applied, otherwise we multiply the data by the value provided\n",
    "          (after applying all other transformations).\n",
    "        preprocessing_function: function that will be applied on each input. The\n",
    "          function will run after the image is resized and augmented.\n",
    "            The function should take one argument: one image (Numpy tensor with\n",
    "              rank 3), and should output a Numpy tensor with the same shape.\n",
    "        data_format: Image data format, either \"channels_first\" or\n",
    "          \"channels_last\". \"channels_last\" mode means that the images should\n",
    "          have shape `(samples, height, width, channels)`, \"channels_first\" mode\n",
    "          means that the images should have shape `(samples, channels, height,\n",
    "          width)`.  It defaults to the `image_data_format` value found in your\n",
    "          Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
    "          it will be \"channels_last\".\n",
    "        validation_split: Float. Fraction of images reserved for validation\n",
    "          (strictly between 0 and 1).\n",
    "        dtype: Dtype to use for the generated arrays.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If the value of the argument, `data_format` is other than\n",
    "            `\"channels_last\"` or `\"channels_first\"`.\n",
    "      ValueError: If the value of the argument, `validation_split` > 1\n",
    "            or `validation_split` < 0.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    Example of using `.flow(x, y)`:\n",
    "\n",
    "    ```python\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    y_train = utils.to_categorical(y_train, num_classes)\n",
    "    y_test = utils.to_categorical(y_test, num_classes)\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=32,\n",
    "             subset='training'),\n",
    "             validation_data=datagen.flow(x_train, y_train,\n",
    "             batch_size=8, subset='validation'),\n",
    "             steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "    # here's a more \"manual\" example\n",
    "    for e in range(epochs):\n",
    "        print('Epoch', e)\n",
    "        batches = 0\n",
    "        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "            model.fit(x_batch, y_batch)\n",
    "            batches += 1\n",
    "            if batches >= len(x_train) / 32:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "    ```\n",
    "\n",
    "    Example of using `.flow_from_directory(directory)`:\n",
    "\n",
    "    ```python\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            'data/train',\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            'data/validation',\n",
    "            target_size=(150, 150),\n",
    "            batch_size=32,\n",
    "            class_mode='binary')\n",
    "    model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=2000,\n",
    "            epochs=50,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=800)\n",
    "    ```\n",
    "\n",
    "    Example of transforming images and masks together.\n",
    "\n",
    "    ```python\n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=90,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(images, augment=True, seed=seed)\n",
    "    mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        'data/images',\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        'data/masks',\n",
    "        class_mode=None,\n",
    "        seed=seed)\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-6,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        brightness_range=None,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode=\"nearest\",\n",
    "        cval=0.0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0,\n",
    "        interpolation_order=1,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "\n",
    "        self.featurewise_center = featurewise_center\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.featurewise_std_normalization = featurewise_std_normalization\n",
    "        self.samplewise_std_normalization = samplewise_std_normalization\n",
    "        self.zca_whitening = zca_whitening\n",
    "        self.zca_epsilon = zca_epsilon\n",
    "        self.rotation_range = rotation_range\n",
    "        self.width_shift_range = width_shift_range\n",
    "        self.height_shift_range = height_shift_range\n",
    "        self.shear_range = shear_range\n",
    "        self.zoom_range = zoom_range\n",
    "        self.channel_shift_range = channel_shift_range\n",
    "        self.fill_mode = fill_mode\n",
    "        self.cval = cval\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.vertical_flip = vertical_flip\n",
    "        self.rescale = rescale\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.dtype = dtype\n",
    "        self.interpolation_order = interpolation_order\n",
    "\n",
    "        if data_format not in {\"channels_last\", \"channels_first\"}:\n",
    "            raise ValueError(\n",
    "                '`data_format` should be `\"channels_last\"` '\n",
    "                \"(channel after row and column) or \"\n",
    "                '`\"channels_first\"` (channel before row and column). '\n",
    "                \"Received: %s\" % data_format\n",
    "            )\n",
    "        self.data_format = data_format\n",
    "        if data_format == \"channels_first\":\n",
    "            self.channel_axis = 1\n",
    "            self.row_axis = 2\n",
    "            self.col_axis = 3\n",
    "        if data_format == \"channels_last\":\n",
    "            self.channel_axis = 3\n",
    "            self.row_axis = 1\n",
    "            self.col_axis = 2\n",
    "        if validation_split and not 0 < validation_split < 1:\n",
    "            raise ValueError(\n",
    "                \"`validation_split` must be strictly between 0 and 1. \"\n",
    "                \" Received: %s\" % validation_split\n",
    "            )\n",
    "        self._validation_split = validation_split\n",
    "\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.zca_whitening_matrix = None\n",
    "\n",
    "        if isinstance(zoom_range, (float, int)):\n",
    "            self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n",
    "        elif len(zoom_range) == 2 and all(\n",
    "            isinstance(val, (float, int)) for val in zoom_range\n",
    "        ):\n",
    "            self.zoom_range = [zoom_range[0], zoom_range[1]]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`zoom_range` should be a float or \"\n",
    "                \"a tuple or list of two floats. \"\n",
    "                \"Received: %s\" % (zoom_range,)\n",
    "            )\n",
    "        if zca_whitening:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening`, which overrides \"\n",
    "                    \"setting of `featurewise_center`.\"\n",
    "                )\n",
    "            if featurewise_std_normalization:\n",
    "                self.featurewise_std_normalization = False\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening` \"\n",
    "                    \"which overrides setting of\"\n",
    "                    \"`featurewise_std_normalization`.\"\n",
    "                )\n",
    "        if featurewise_std_normalization:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_std_normalization`, \"\n",
    "                    \"which overrides setting of \"\n",
    "                    \"`featurewise_center`.\"\n",
    "                )\n",
    "        if samplewise_std_normalization:\n",
    "            if not samplewise_center:\n",
    "                self.samplewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`samplewise_std_normalization`, \"\n",
    "                    \"which overrides setting of \"\n",
    "                    \"`samplewise_center`.\"\n",
    "                )\n",
    "        if brightness_range is not None:\n",
    "            if (\n",
    "                not isinstance(brightness_range, (tuple, list))\n",
    "                or len(brightness_range) != 2\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"`brightness_range should be tuple or list of two floats. \"\n",
    "                    \"Received: %s\" % (brightness_range,)\n",
    "                )\n",
    "        self.brightness_range = brightness_range\n",
    "\n",
    "    def flow(\n",
    "        self,\n",
    "        x,\n",
    "        y=None,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        ignore_class_split=False,\n",
    "        subset=None,\n",
    "    ):\n",
    "        \"\"\"Takes data & label arrays, generates batches of augmented data.\n",
    "\n",
    "        Args:\n",
    "            x: Input data. Numpy array of rank 4 or a tuple. If tuple, the first\n",
    "              element should contain the images and the second element another\n",
    "              numpy array or a list of numpy arrays that gets passed to the\n",
    "              output without any modifications. Can be used to feed the model\n",
    "              miscellaneous data along with the images. In case of grayscale\n",
    "              data, the channels axis of the image array should have value 1, in\n",
    "              case of RGB data, it should have value 3, and in case of RGBA\n",
    "              data, it should have value 4.\n",
    "            y: Labels.\n",
    "            batch_size: Int (default: 32).\n",
    "            shuffle: Boolean (default: True).\n",
    "            sample_weight: Sample weights.\n",
    "            seed: Int (default: None).\n",
    "            save_to_dir: None or str (default: None). This allows you to\n",
    "              optionally specify a directory to which to save the augmented\n",
    "              pictures being generated (useful for visualizing what you are\n",
    "              doing).\n",
    "            save_prefix: Str (default: `''`). Prefix to use for filenames of\n",
    "              saved pictures (only relevant if `save_to_dir` is set).\n",
    "            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
    "              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n",
    "              \"png\".\n",
    "            ignore_class_split: Boolean (default: False), ignore difference\n",
    "              in number of classes in labels across train and validation\n",
    "              split (useful for non-classification tasks)\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "              `validation_split` is set in `ImageDataGenerator`.\n",
    "\n",
    "        Returns:\n",
    "            An `Iterator` yielding tuples of `(x, y)`\n",
    "                where `x` is a numpy array of image data\n",
    "                (in the case of a single image input) or a list\n",
    "                of numpy arrays (in the case with\n",
    "                additional inputs) and `y` is a numpy array\n",
    "                of corresponding labels. If 'sample_weight' is not None,\n",
    "                the yielded tuples are of the form `(x, y, sample_weight)`.\n",
    "                If `y` is None, only the numpy array `x` is returned.\n",
    "        Raises:\n",
    "          ValueError: If the Value of the argument, `subset` is other than\n",
    "                \"training\" or \"validation\".\n",
    "\n",
    "        \"\"\"\n",
    "        return NumpyArrayIterator(\n",
    "            x,\n",
    "            y,\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            sample_weight=sample_weight,\n",
    "            seed=seed,\n",
    "            data_format=self.data_format,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            ignore_class_split=ignore_class_split,\n",
    "            subset=subset,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def flow_from_directory(\n",
    "        self,\n",
    "        directory,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        follow_links=False,\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "    ):\n",
    "        \"\"\"Takes the path to a directory & generates batches of augmented data.\n",
    "\n",
    "        Args:\n",
    "            directory: string, path to the target directory. It should contain\n",
    "              one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images\n",
    "              inside each of the subdirectories directory tree will be included\n",
    "              in the generator. See [this script](\n",
    "              https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
    "              for more details.\n",
    "            target_size: Tuple of integers `(height, width)`, defaults to `(256,\n",
    "              256)`. The dimensions to which all images found will be resized.\n",
    "            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "              Whether the images will be converted to have 1, 3, or 4 channels.\n",
    "            classes: Optional list of class subdirectories (e.g. `['dogs',\n",
    "              'cats']`). Default: None. If not provided, the list of classes\n",
    "              will be automatically inferred from the subdirectory\n",
    "              names/structure under `directory`, where each subdirectory will be\n",
    "              treated as a different class (and the order of the classes, which\n",
    "              will map to the label indices, will be alphanumeric). The\n",
    "              dictionary containing the mapping from class names to class\n",
    "              indices can be obtained via the attribute `class_indices`.\n",
    "            class_mode: One of \"categorical\", \"binary\", \"sparse\",\n",
    "                \"input\", or None. Default: \"categorical\".\n",
    "                Determines the type of label arrays that are returned:\n",
    "                - \"categorical\" will be 2D one-hot encoded labels,\n",
    "                - \"binary\" will be 1D binary labels,\n",
    "                    \"sparse\" will be 1D integer labels,\n",
    "                - \"input\" will be images identical\n",
    "                    to input images (mainly used to work with autoencoders).\n",
    "                - If None, no labels are returned\n",
    "                  (the generator will only yield batches of image data,\n",
    "                  which is useful to use with `model.predict_generator()`).\n",
    "                  Please note that in case of class_mode None,\n",
    "                  the data still needs to reside in a subdirectory\n",
    "                  of `directory` for it to work correctly.\n",
    "            batch_size: Size of the batches of data (default: 32).\n",
    "            shuffle: Whether to shuffle the data (default: True) If set to\n",
    "              False, sorts the data in alphanumeric order.\n",
    "            seed: Optional random seed for shuffling and transformations.\n",
    "            save_to_dir: None or str (default: None). This allows you to\n",
    "              optionally specify a directory to which to save the augmented\n",
    "              pictures being generated (useful for visualizing what you are\n",
    "              doing).\n",
    "            save_prefix: Str. Prefix to use for filenames of saved pictures\n",
    "              (only relevant if `save_to_dir` is set).\n",
    "            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
    "              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n",
    "              \"png\".\n",
    "            follow_links: Whether to follow symlinks inside\n",
    "                class subdirectories (default: False).\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "              `validation_split` is set in `ImageDataGenerator`.\n",
    "            interpolation: Interpolation method used to resample the image if\n",
    "              the target size is different from that of the loaded image.\n",
    "              Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
    "              If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
    "              supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
    "              `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
    "            keep_aspect_ratio: Boolean, whether to resize images to a target\n",
    "              size without aspect ratio distortion. The image is cropped in\n",
    "              the center with target aspect ratio before resizing.\n",
    "\n",
    "        Returns:\n",
    "            A `DirectoryIterator` yielding tuples of `(x, y)`\n",
    "                where `x` is a numpy array containing a batch\n",
    "                of images with shape `(batch_size, *target_size, channels)`\n",
    "                and `y` is a numpy array of corresponding labels.\n",
    "        \"\"\"\n",
    "        return DirectoryIterator(\n",
    "            directory,\n",
    "            self,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            keep_aspect_ratio=keep_aspect_ratio,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            follow_links=follow_links,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def flow_from_dataframe(\n",
    "        self,\n",
    "        dataframe,\n",
    "        directory=None,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        weight_col=None,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        validate_filenames=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Takes the dataframe and the path to a directory + generates batches.\n",
    "\n",
    "         The generated batches contain augmented/normalized data.\n",
    "\n",
    "        **A simple tutorial can be found **[here](\n",
    "                                    http://bit.ly/keras_flow_from_dataframe).\n",
    "\n",
    "        Args:\n",
    "            dataframe: Pandas dataframe containing the filepaths relative to\n",
    "                `directory` (or absolute paths if `directory` is None) of the\n",
    "                images in a string column. It should include other column/s\n",
    "                depending on the `class_mode`:\n",
    "                - if `class_mode` is `\"categorical\"` (default value) it must\n",
    "                    include the `y_col` column with the class/es of each image.\n",
    "                    Values in column can be string/list/tuple if a single class\n",
    "                    or list/tuple if multiple classes.\n",
    "                - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n",
    "                    the given `y_col` column with class values as strings.\n",
    "                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should\n",
    "                    contain the columns specified in `y_col`.\n",
    "                - if `class_mode` is `\"input\"` or `None` no extra column is\n",
    "                    needed.\n",
    "            directory: string, path to the directory to read images from. If\n",
    "              `None`, data in `x_col` column should be absolute paths.\n",
    "            x_col: string, column in `dataframe` that contains the filenames (or\n",
    "              absolute paths if `directory` is `None`).\n",
    "            y_col: string or list, column/s in `dataframe` that has the target\n",
    "              data.\n",
    "            weight_col: string, column in `dataframe` that contains the sample\n",
    "                weights. Default: `None`.\n",
    "            target_size: tuple of integers `(height, width)`, default: `(256,\n",
    "              256)`. The dimensions to which all images found will be resized.\n",
    "            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "              Whether the images will be converted to have 1 or 3 color\n",
    "              channels.\n",
    "            classes: optional list of classes (e.g. `['dogs', 'cats']`). Default\n",
    "              is None. If not provided, the list of classes will be\n",
    "              automatically inferred from the `y_col`, which will map to the\n",
    "              label indices, will be alphanumeric). The dictionary containing\n",
    "              the mapping from class names to class indices can be obtained via\n",
    "              the attribute `class_indices`.\n",
    "            class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
    "                \"raw\", sparse\" or None. Default: \"categorical\".\n",
    "                Mode for yielding the targets:\n",
    "                - `\"binary\"`: 1D numpy array of binary labels,\n",
    "                - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n",
    "                  Supports multi-label output.\n",
    "                - `\"input\"`: images identical to input images (mainly used to\n",
    "                  work with autoencoders),\n",
    "                - `\"multi_output\"`: list with the values of the different\n",
    "                  columns,\n",
    "                - `\"raw\"`: numpy array of values in `y_col` column(s),\n",
    "                - `\"sparse\"`: 1D numpy array of integer labels,\n",
    "                - `None`, no targets are returned (the generator will only yield\n",
    "                  batches of image data, which is useful to use in\n",
    "                  `model.predict()`).\n",
    "            batch_size: size of the batches of data (default: 32).\n",
    "            shuffle: whether to shuffle the data (default: True)\n",
    "            seed: optional random seed for shuffling and transformations.\n",
    "            save_to_dir: None or str (default: None). This allows you to\n",
    "              optionally specify a directory to which to save the augmented\n",
    "              pictures being generated (useful for visualizing what you are\n",
    "              doing).\n",
    "            save_prefix: str. Prefix to use for filenames of saved pictures\n",
    "              (only relevant if `save_to_dir` is set).\n",
    "            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
    "              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n",
    "              \"png\".\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "              `validation_split` is set in `ImageDataGenerator`.\n",
    "            interpolation: Interpolation method used to resample the image if\n",
    "              the target size is different from that of the loaded image.\n",
    "              Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
    "              If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
    "              supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
    "              `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
    "            validate_filenames: Boolean, whether to validate image filenames in\n",
    "              `x_col`. If `True`, invalid images will be ignored. Disabling this\n",
    "              option can lead to speed-up in the execution of this function.\n",
    "              Defaults to `True`.\n",
    "            **kwargs: legacy arguments for raising deprecation warnings.\n",
    "\n",
    "        Returns:\n",
    "            A `DataFrameIterator` yielding tuples of `(x, y)`\n",
    "            where `x` is a numpy array containing a batch\n",
    "            of images with shape `(batch_size, *target_size, channels)`\n",
    "            and `y` is a numpy array of corresponding labels.\n",
    "        \"\"\"\n",
    "        if \"has_ext\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"has_ext is deprecated, filenames in the dataframe have \"\n",
    "                \"to match the exact filenames in disk.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        if \"sort\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"sort is deprecated, batches will be created in the\"\n",
    "                \"same order than the filenames provided if shuffle\"\n",
    "                \"is set to False.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        if class_mode == \"other\":\n",
    "            warnings.warn(\n",
    "                '`class_mode` \"other\" is deprecated, please use '\n",
    "                '`class_mode` \"raw\".',\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "            class_mode = \"raw\"\n",
    "        if \"drop_duplicates\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"drop_duplicates is deprecated, you can drop duplicates \"\n",
    "                \"by using the pandas.DataFrame.drop_duplicates method.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        return DataFrameIterator(\n",
    "            dataframe,\n",
    "            directory,\n",
    "            self,\n",
    "            x_col=x_col,\n",
    "            y_col=y_col,\n",
    "            weight_col=weight_col,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            validate_filenames=validate_filenames,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def standardize(self, x):\n",
    "        \"\"\"Applies the normalization configuration in-place to a batch of\n",
    "        inputs.\n",
    "\n",
    "        `x` is changed in-place since the function is mainly used internally\n",
    "        to standardize images and feed them to your network. If a copy of `x`\n",
    "        would be created instead it would have a significant performance cost.\n",
    "        If you want to apply this method without changing the input in-place\n",
    "        you can call the method creating a copy before:\n",
    "\n",
    "        standardize(np.copy(x))\n",
    "\n",
    "        Args:\n",
    "            x: Batch of inputs to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            The inputs, normalized.\n",
    "        \"\"\"\n",
    "        if self.preprocessing_function:\n",
    "            x = self.preprocessing_function(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "        if self.samplewise_center:\n",
    "            x -= np.mean(x, keepdims=True)\n",
    "        if self.samplewise_std_normalization:\n",
    "            x /= np.std(x, keepdims=True) + 1e-6\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            if self.mean is not None:\n",
    "                x -= self.mean\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_center`, but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        if self.featurewise_std_normalization:\n",
    "            if self.std is not None:\n",
    "                x /= self.std + 1e-6\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_std_normalization`, \"\n",
    "                    \"but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        if self.zca_whitening:\n",
    "            if self.zca_whitening_matrix is not None:\n",
    "                flat_x = x.reshape(-1, np.prod(x.shape[-3:]))\n",
    "                white_x = flat_x @ self.zca_whitening_matrix\n",
    "                x = np.reshape(white_x, x.shape)\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening`, but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        return x\n",
    "\n",
    "    def get_random_transform(self, img_shape, seed=None):\n",
    "        \"\"\"Generates random parameters for a transformation.\n",
    "\n",
    "        Args:\n",
    "            img_shape: Tuple of integers.\n",
    "                Shape of the image that is transformed.\n",
    "            seed: Random seed.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing randomly chosen parameters describing the\n",
    "            transformation.\n",
    "        \"\"\"\n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        if self.rotation_range:\n",
    "            theta = np.random.uniform(-self.rotation_range, self.rotation_range)\n",
    "        else:\n",
    "            theta = 0\n",
    "\n",
    "        if self.height_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                tx = np.random.choice(self.height_shift_range)\n",
    "                tx *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                tx = np.random.uniform(\n",
    "                    -self.height_shift_range, self.height_shift_range\n",
    "                )\n",
    "            if np.max(self.height_shift_range) < 1:\n",
    "                tx *= img_shape[img_row_axis]\n",
    "        else:\n",
    "            tx = 0\n",
    "\n",
    "        if self.width_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                ty = np.random.choice(self.width_shift_range)\n",
    "                ty *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                ty = np.random.uniform(\n",
    "                    -self.width_shift_range, self.width_shift_range\n",
    "                )\n",
    "            if np.max(self.width_shift_range) < 1:\n",
    "                ty *= img_shape[img_col_axis]\n",
    "        else:\n",
    "            ty = 0\n",
    "\n",
    "        if self.shear_range:\n",
    "            shear = np.random.uniform(-self.shear_range, self.shear_range)\n",
    "        else:\n",
    "            shear = 0\n",
    "\n",
    "        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n",
    "            zx, zy = 1, 1\n",
    "        else:\n",
    "            zx, zy = np.random.uniform(\n",
    "                self.zoom_range[0], self.zoom_range[1], 2\n",
    "            )\n",
    "\n",
    "        flip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\n",
    "        flip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n",
    "\n",
    "        channel_shift_intensity = None\n",
    "        if self.channel_shift_range != 0:\n",
    "            channel_shift_intensity = np.random.uniform(\n",
    "                -self.channel_shift_range, self.channel_shift_range\n",
    "            )\n",
    "\n",
    "        brightness = None\n",
    "        if self.brightness_range is not None:\n",
    "            brightness = np.random.uniform(\n",
    "                self.brightness_range[0], self.brightness_range[1]\n",
    "            )\n",
    "\n",
    "        transform_parameters = {\n",
    "            \"theta\": theta,\n",
    "            \"tx\": tx,\n",
    "            \"ty\": ty,\n",
    "            \"shear\": shear,\n",
    "            \"zx\": zx,\n",
    "            \"zy\": zy,\n",
    "            \"flip_horizontal\": flip_horizontal,\n",
    "            \"flip_vertical\": flip_vertical,\n",
    "            \"channel_shift_intensity\": channel_shift_intensity,\n",
    "            \"brightness\": brightness,\n",
    "        }\n",
    "\n",
    "        return transform_parameters\n",
    "\n",
    "    def apply_transform(self, x, transform_parameters):\n",
    "        \"\"\"Applies a transformation to an image according to given parameters.\n",
    "\n",
    "        Args:\n",
    "            x: 3D tensor, single image.\n",
    "            transform_parameters: Dictionary with string - parameter pairs\n",
    "                describing the transformation.\n",
    "                Currently, the following parameters\n",
    "                from the dictionary are used:\n",
    "                - `'theta'`: Float. Rotation angle in degrees.\n",
    "                - `'tx'`: Float. Shift in the x direction.\n",
    "                - `'ty'`: Float. Shift in the y direction.\n",
    "                - `'shear'`: Float. Shear angle in degrees.\n",
    "                - `'zx'`: Float. Zoom in the x direction.\n",
    "                - `'zy'`: Float. Zoom in the y direction.\n",
    "                - `'flip_horizontal'`: Boolean. Horizontal flip.\n",
    "                - `'flip_vertical'`: Boolean. Vertical flip.\n",
    "                - `'channel_shift_intensity'`: Float. Channel shift intensity.\n",
    "                - `'brightness'`: Float. Brightness shift intensity.\n",
    "\n",
    "        Returns:\n",
    "            A transformed version of the input (same shape).\n",
    "        \"\"\"\n",
    "        # x is a single image, so it doesn't have image number at index 0\n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "        img_channel_axis = self.channel_axis - 1\n",
    "\n",
    "        x = apply_affine_transform(\n",
    "            x,\n",
    "            transform_parameters.get(\"theta\", 0),\n",
    "            transform_parameters.get(\"tx\", 0),\n",
    "            transform_parameters.get(\"ty\", 0),\n",
    "            transform_parameters.get(\"shear\", 0),\n",
    "            transform_parameters.get(\"zx\", 1),\n",
    "            transform_parameters.get(\"zy\", 1),\n",
    "            row_axis=img_row_axis,\n",
    "            col_axis=img_col_axis,\n",
    "            channel_axis=img_channel_axis,\n",
    "            fill_mode=self.fill_mode,\n",
    "            cval=self.cval,\n",
    "            order=self.interpolation_order,\n",
    "        )\n",
    "\n",
    "        if transform_parameters.get(\"channel_shift_intensity\") is not None:\n",
    "            x = apply_channel_shift(\n",
    "                x,\n",
    "                transform_parameters[\"channel_shift_intensity\"],\n",
    "                img_channel_axis,\n",
    "            )\n",
    "\n",
    "        if transform_parameters.get(\"flip_horizontal\", False):\n",
    "            x = flip_axis(x, img_col_axis)\n",
    "\n",
    "        if transform_parameters.get(\"flip_vertical\", False):\n",
    "            x = flip_axis(x, img_row_axis)\n",
    "\n",
    "        if transform_parameters.get(\"brightness\") is not None:\n",
    "            x = apply_brightness_shift(\n",
    "                x, transform_parameters[\"brightness\"], False\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x, seed=None):\n",
    "        \"\"\"Applies a random transformation to an image.\n",
    "\n",
    "        Args:\n",
    "            x: 3D tensor, single image.\n",
    "            seed: Random seed.\n",
    "\n",
    "        Returns:\n",
    "            A randomly transformed version of the input (same shape).\n",
    "        \"\"\"\n",
    "        params = self.get_random_transform(x.shape, seed)\n",
    "        return self.apply_transform(x, params)\n",
    "\n",
    "    def fit(self, x, augment=False, rounds=1, seed=None):\n",
    "        \"\"\"Fits the data generator to some sample data.\n",
    "\n",
    "        This computes the internal data stats related to the\n",
    "        data-dependent transformations, based on an array of sample data.\n",
    "\n",
    "        Only required if `featurewise_center` or\n",
    "        `featurewise_std_normalization` or `zca_whitening` are set to True.\n",
    "\n",
    "        When `rescale` is set to a value, rescaling is applied to\n",
    "        sample data before computing the internal data stats.\n",
    "\n",
    "        Args:\n",
    "            x: Sample data. Should have rank 4.\n",
    "             In case of grayscale data,\n",
    "             the channels axis should have value 1, in case\n",
    "             of RGB data, it should have value 3, and in case\n",
    "             of RGBA data, it should have value 4.\n",
    "            augment: Boolean (default: False).\n",
    "                Whether to fit on randomly augmented samples.\n",
    "            rounds: Int (default: 1).\n",
    "                If using data augmentation (`augment=True`),\n",
    "                this is how many augmentation passes over the data to use.\n",
    "            seed: Int (default: None). Random seed.\n",
    "        \"\"\"\n",
    "        x = np.asarray(x, dtype=self.dtype)\n",
    "        if x.ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input to `.fit()` should have rank 4. \"\n",
    "                \"Got array with shape: \" + str(x.shape)\n",
    "            )\n",
    "        if x.shape[self.channel_axis] not in {1, 3, 4}:\n",
    "            warnings.warn(\n",
    "                \"Expected input to be images (as Numpy array) \"\n",
    "                'following the data format convention \"'\n",
    "                + self.data_format\n",
    "                + '\" (channels on axis '\n",
    "                + str(self.channel_axis)\n",
    "                + \"), i.e. expected \"\n",
    "                \"either 1, 3 or 4 channels on axis \"\n",
    "                + str(self.channel_axis)\n",
    "                + \". \"\n",
    "                \"However, it was passed an array with shape \"\n",
    "                + str(x.shape)\n",
    "                + \" (\"\n",
    "                + str(x.shape[self.channel_axis])\n",
    "                + \" channels).\"\n",
    "            )\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        x = np.copy(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "\n",
    "        if augment:\n",
    "            ax = np.zeros(\n",
    "                tuple([rounds * x.shape[0]] + list(x.shape)[1:]),\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "            for r in range(rounds):\n",
    "                for i in range(x.shape[0]):\n",
    "                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n",
    "            x = ax\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            x -= self.mean\n",
    "\n",
    "        if self.featurewise_std_normalization:\n",
    "            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.std = np.reshape(self.std, broadcast_shape)\n",
    "            x /= self.std + 1e-6\n",
    "\n",
    "        if self.zca_whitening:\n",
    "            n = len(x)\n",
    "            flat_x = np.reshape(x, (n, -1))\n",
    "\n",
    "            u, s, _ = np.linalg.svd(flat_x.T, full_matrices=False)\n",
    "            s_inv = np.sqrt(n) / (s + self.zca_epsilon)\n",
    "            self.zca_whitening_matrix = (u * s_inv).dot(u.T)\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_rotation\")\n",
    "def random_rotation(\n",
    "    x,\n",
    "    rg,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \"\"\"Performs a random rotation of a Numpy image tensor.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.random_rotation` does not operate\n",
    "    on tensors and is not recommended for new code. Prefer\n",
    "    `tf.keras.layers.RandomRotation` which provides equivalent functionality as\n",
    "    a preprocessing layer. For more information, see the tutorial for\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        rg: Rotation range, in degrees.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "\n",
    "    Returns:\n",
    "        Rotated Numpy image tensor.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(-rg, rg)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        theta=theta,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_shift\")\n",
    "def random_shift(\n",
    "    x,\n",
    "    wrg,\n",
    "    hrg,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \"\"\"Performs a random spatial shift of a Numpy image tensor.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.random_shift` does not operate on\n",
    "    tensors and is not recommended for new code. Prefer\n",
    "    `tf.keras.layers.RandomTranslation` which provides equivalent functionality\n",
    "    as a preprocessing layer. For more information, see the tutorial for\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        wrg: Width shift range, as a float fraction of the width.\n",
    "        hrg: Height shift range, as a float fraction of the height.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "\n",
    "    Returns:\n",
    "        Shifted Numpy image tensor.\n",
    "    \"\"\"\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    tx = np.random.uniform(-hrg, hrg) * h\n",
    "    ty = np.random.uniform(-wrg, wrg) * w\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        tx=tx,\n",
    "        ty=ty,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_shear\")\n",
    "def random_shear(\n",
    "    x,\n",
    "    intensity,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \"\"\"Performs a random spatial shear of a Numpy image tensor.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity: Transformation intensity in degrees.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "\n",
    "    Returns:\n",
    "        Sheared Numpy image tensor.\n",
    "    \"\"\"\n",
    "    shear = np.random.uniform(-intensity, intensity)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        shear=shear,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_zoom\")\n",
    "def random_zoom(\n",
    "    x,\n",
    "    zoom_range,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.random_zoom` does not operate on\n",
    "    tensors and is not recommended for new code. Prefer\n",
    "    `tf.keras.layers.RandomZoom` which provides equivalent functionality as\n",
    "    a preprocessing layer. For more information, see the tutorial for\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        zoom_range: Tuple of floats; zoom range for width and height.\n",
    "        row_axis: Index of axis for rows in the input tensor.\n",
    "        col_axis: Index of axis for columns in the input tensor.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        interpolation_order: int, order of spline interpolation.\n",
    "            see `ndimage.interpolation.affine_transform`\n",
    "\n",
    "    Returns:\n",
    "        Zoomed Numpy image tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `zoom_range` isn't a tuple.\n",
    "    \"\"\"\n",
    "    if len(zoom_range) != 2:\n",
    "        raise ValueError(\n",
    "            \"`zoom_range` should be a tuple or list of two\"\n",
    "            \" floats. Received: %s\" % (zoom_range,)\n",
    "        )\n",
    "\n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        zx=zx,\n",
    "        zy=zy,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_channel_shift\")\n",
    "def apply_channel_shift(x, intensity, channel_axis=0):\n",
    "    \"\"\"Performs a channel shift.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity: Transformation intensity.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "\n",
    "    Returns:\n",
    "        Numpy image tensor.\n",
    "    \"\"\"\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    channel_images = [\n",
    "        np.clip(x_channel + intensity, min_x, max_x) for x_channel in x\n",
    "    ]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_channel_shift\")\n",
    "def random_channel_shift(x, intensity_range, channel_axis=0):\n",
    "    \"\"\"Performs a random channel shift.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity_range: Transformation intensity.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "\n",
    "    Returns:\n",
    "        Numpy image tensor.\n",
    "    \"\"\"\n",
    "    intensity = np.random.uniform(-intensity_range, intensity_range)\n",
    "    return apply_channel_shift(x, intensity, channel_axis=channel_axis)\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_brightness_shift\")\n",
    "def apply_brightness_shift(x, brightness, scale=True):\n",
    "    \"\"\"Performs a brightness shift.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        brightness: Float. The new brightness value.\n",
    "        scale: Whether to rescale the image such that minimum and maximum values\n",
    "            are 0 and 255 respectively. Default: True.\n",
    "\n",
    "    Returns:\n",
    "        Numpy image tensor.\n",
    "\n",
    "    Raises:\n",
    "        ImportError: if PIL is not available.\n",
    "    \"\"\"\n",
    "    if ImageEnhance is None:\n",
    "        raise ImportError(\n",
    "            \"Using brightness shifts requires PIL. \" \"Install PIL or Pillow.\"\n",
    "        )\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    local_scale = (x_min < 0) or (x_max > 255)\n",
    "    x = image_utils.array_to_img(x, scale=local_scale or scale)\n",
    "    x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n",
    "    x = imgenhancer_Brightness.enhance(brightness)\n",
    "    x = image_utils.img_to_array(x)\n",
    "    if not scale and local_scale:\n",
    "        x = x / 255 * (x_max - x_min) + x_min\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_brightness\")\n",
    "def random_brightness(x, brightness_range, scale=True):\n",
    "    \"\"\"Performs a random brightness shift.\n",
    "\n",
    "    Deprecated: `tf.keras.preprocessing.image.random_brightness` does not\n",
    "    operate on tensors and is not recommended for new code. Prefer\n",
    "    `tf.keras.layers.RandomBrightness` which provides equivalent functionality\n",
    "    as a preprocessing layer. For more information, see the tutorial for\n",
    "    [augmenting images](\n",
    "    https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
    "    the [preprocessing layer guide](\n",
    "    https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        brightness_range: Tuple of floats; brightness range.\n",
    "        scale: Whether to rescale the image such that minimum and maximum values\n",
    "            are 0 and 255 respectively. Default: True.\n",
    "\n",
    "    Returns:\n",
    "        Numpy image tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `brightness_range` isn't a tuple.\n",
    "    \"\"\"\n",
    "    if len(brightness_range) != 2:\n",
    "        raise ValueError(\n",
    "            \"`brightness_range should be tuple or list of two floats. \"\n",
    "            \"Received: %s\" % (brightness_range,)\n",
    "        )\n",
    "\n",
    "    u = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "    return apply_brightness_shift(x, u, scale)\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 - 0.5\n",
    "    o_y = float(y) / 2 - 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_affine_transform\")\n",
    "def apply_affine_transform(\n",
    "    x,\n",
    "    theta=0,\n",
    "    tx=0,\n",
    "    ty=0,\n",
    "    shear=0,\n",
    "    zx=1,\n",
    "    zy=1,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    order=1,\n",
    "):\n",
    "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
    "\n",
    "    Args:\n",
    "        x: 3D numpy array - a 2D image with one or more channels.\n",
    "        theta: Rotation angle in degrees.\n",
    "        tx: Width shift.\n",
    "        ty: Heigh shift.\n",
    "        shear: Shear angle in degrees.\n",
    "        zx: Zoom in x direction.\n",
    "        zy: Zoom in y direction\n",
    "        row_axis: Index of axis for rows (aka Y axis) in the input\n",
    "            image. Direction: left to right.\n",
    "        col_axis: Index of axis for columns (aka X axis) in the input\n",
    "            image. Direction: top to bottom.\n",
    "        channel_axis: Index of axis for channels in the input image.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        order: int, order of interpolation\n",
    "\n",
    "    Returns:\n",
    "        The transformed version of the input.\n",
    "\n",
    "    Raises:\n",
    "        ImportError: if SciPy is not available.\n",
    "    \"\"\"\n",
    "    if scipy is None:\n",
    "        raise ImportError(\n",
    "            \"Image transformations require SciPy. \" \"Install SciPy.\"\n",
    "        )\n",
    "\n",
    "    # Input sanity checks:\n",
    "    # 1. x must 2D image with one or more channels (i.e., a 3D tensor)\n",
    "    # 2. channels must be either first or last dimension\n",
    "    if np.unique([row_axis, col_axis, channel_axis]).size != 3:\n",
    "        raise ValueError(\n",
    "            \"'row_axis', 'col_axis', and 'channel_axis'\" \" must be distinct\"\n",
    "        )\n",
    "\n",
    "    # shall we support negative indices?\n",
    "    valid_indices = set([0, 1, 2])\n",
    "    actual_indices = set([row_axis, col_axis, channel_axis])\n",
    "    if actual_indices != valid_indices:\n",
    "        raise ValueError(\n",
    "            f\"Invalid axis' indices: {actual_indices - valid_indices}\"\n",
    "        )\n",
    "\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError(\"Input arrays must be multi-channel 2D images.\")\n",
    "    if channel_axis not in [0, 2]:\n",
    "        raise ValueError(\n",
    "            \"Channels are allowed and the first and last dimensions.\"\n",
    "        )\n",
    "\n",
    "    transform_matrix = None\n",
    "    if theta != 0:\n",
    "        theta = np.deg2rad(theta)\n",
    "        rotation_matrix = np.array(\n",
    "            [\n",
    "                [np.cos(theta), -np.sin(theta), 0],\n",
    "                [np.sin(theta), np.cos(theta), 0],\n",
    "                [0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        transform_matrix = rotation_matrix\n",
    "\n",
    "    if tx != 0 or ty != 0:\n",
    "        shift_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shift_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
    "\n",
    "    if shear != 0:\n",
    "        shear = np.deg2rad(shear)\n",
    "        shear_matrix = np.array(\n",
    "            [[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]]\n",
    "        )\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shear_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
    "\n",
    "    if zx != 1 or zy != 1:\n",
    "        zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = zoom_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
    "\n",
    "    if transform_matrix is not None:\n",
    "        h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "        transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h, w\n",
    "        )\n",
    "        x = np.rollaxis(x, channel_axis, 0)\n",
    "\n",
    "        # Matrix construction assumes that coordinates are x, y (in that order).\n",
    "        # However, regular numpy arrays use y,x (aka i,j) indexing.\n",
    "        # Possible solution is:\n",
    "        #   1. Swap the x and y axes.\n",
    "        #   2. Apply transform.\n",
    "        #   3. Swap the x and y axes again to restore image-like data ordering.\n",
    "        # Mathematically, it is equivalent to the following transformation:\n",
    "        # M' = PMP, where P is the permutation matrix, M is the original\n",
    "        # transformation matrix.\n",
    "        if col_axis > row_axis:\n",
    "            transform_matrix[:, [0, 1]] = transform_matrix[:, [1, 0]]\n",
    "            transform_matrix[[0, 1]] = transform_matrix[[1, 0]]\n",
    "        final_affine_matrix = transform_matrix[:2, :2]\n",
    "        final_offset = transform_matrix[:2, 2]\n",
    "\n",
    "        channel_images = [\n",
    "            ndimage.interpolation.affine_transform(\n",
    "                x_channel,\n",
    "                final_affine_matrix,\n",
    "                final_offset,\n",
    "                order=order,\n",
    "                mode=fill_mode,\n",
    "                cval=cval,\n",
    "            )\n",
    "            for x_channel in x\n",
    "        ]\n",
    "        x = np.stack(channel_images, axis=0)\n",
    "        x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def img_to_array():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a1b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
